# ════════════════════════════════════════════════════════════════════
#  GitHub Events Streaming Stack
#  ┌──────────────┐    ┌─────────────────────────────────────────┐
#  │   Producer   │───▶│  Kafka (KRaft, no Zookeeper)            │
#  │ (GitHub API) │    │  Topics:                                │
#  └──────────────┘    │    github.events.raw     (raw JSON)     │
#                      └─────────────┬───────────────────────────┘
#                                    │
#                      ┌─────────────▼───────────────────────────┐
#                      │  Consumer / Enricher (Python)            │
#                      │  • Fetches GitHub profile + geo data     │
#                      │  • Writes enriched rows → TimescaleDB   │
#                      └─────────────┬───────────────────────────┘
#                                    │
#                      ┌─────────────▼───────────────────────────┐
#                      │  TimescaleDB (PostgreSQL + time-series)  │
#                      │  • events        (hypertable)            │
#                      │  • country_stats (continuous aggregate)  │
#                      │  • event_stats   (continuous aggregate)  │
#                      └─────────────┬───────────────────────────┘
#                                    │
#                      ┌─────────────▼───────────────────────────┐
#                      │  Grafana  (live dashboards)              │
#                      │  http://localhost:3000                   │
#                      └─────────────────────────────────────────┘
#  Debug UI: Kafka-UI at http://localhost:8080
#
#  Images used (all freely available on Docker Hub):
#    apache/kafka:3.9.0          — official ASF image (KRaft built-in)
#    provectuslabs/kafka-ui:latest
#    timescale/timescaledb:latest-pg16
#    grafana/grafana:latest
# ════════════════════════════════════════════════════════════════════

networks:
  github-stream:
    driver: bridge

volumes:
  kafka-data:
  timescale-data:
  grafana-data:

services:

  # ── Kafka (KRaft combined mode — broker + controller in one) ────
  # Uses the official apache/kafka image (ASF).
  # Bitnami images were removed from Docker Hub in Sept 2025.
  # apache/kafka env vars do NOT use the KAFKA_CFG_ prefix.
  kafka:
    image: apache/kafka:3.9.0
    container_name: kafka
    hostname: kafka
    networks: [github-stream]
    ports:
      - "9092:9092"    # used by other containers on the Docker network
      - "9094:9094"    # mapped to host for local CLI / testing
    volumes:
      - kafka-data:/var/lib/kafka/data
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093

      # Two listeners:
      #   PLAINTEXT  → internal Docker traffic (kafka:9092)
      #   EXTERNAL   → host-machine access     (localhost:9094)
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 48
      KAFKA_LOG_RETENTION_BYTES: 536870912    # 512 MB cap per partition

      # Stable cluster ID (base64-encoded 16-byte UUID).
      # Generate your own with: python3 -c "import uuid,base64; print(base64.urlsafe_b64encode(uuid.uuid4().bytes).decode().rstrip('='))"
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"

    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 8
      start_period: 30s

  # ── Kafka UI (debug / monitoring) ──────────────────────────────
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    networks: [github-stream]
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      kafka:
        condition: service_healthy

  # ── Topic initialisation (runs once then exits) ─────────────────
  kafka-init:
    image: apache/kafka:3.9.0
    container_name: kafka-init
    networks: [github-stream]
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/bash", "-c"]
    command: |
      "
      echo '--- Creating Kafka topics ---'
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 \
        --create --if-not-exists \
        --topic github.events.raw \
        --partitions 3 --replication-factor 1 \
        --config retention.ms=172800000

      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 \
        --create --if-not-exists \
        --topic github.events.enriched \
        --partitions 3 --replication-factor 1 \
        --config retention.ms=172800000

      echo '--- Topics ready ---'
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list
      "
    restart: "no"

  # ── TimescaleDB ─────────────────────────────────────────────────
  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: timescaledb
    networks: [github-stream]
    ports:
      - "5432:5432"
    volumes:
      - timescale-data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    environment:
      POSTGRES_DB:       github_events
      POSTGRES_USER:     github
      POSTGRES_PASSWORD: github_secret
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U github -d github_events"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ── GitHub API Producer ─────────────────────────────────────────
  producer:
    build:
      context: ./producer
      dockerfile: Dockerfile
    container_name: github-producer
    networks: [github-stream]
    depends_on:
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      GITHUB_TOKEN:            ${GITHUB_TOKEN:-}
      POLL_INTERVAL_SECONDS:   "10"
      MAX_PAGES:               "3"
    restart: unless-stopped

  # ── Consumer / Enricher / DB Writer ────────────────────────────
  consumer:
    build:
      context: ./consumer
      dockerfile: Dockerfile
    container_name: github-consumer
    networks: [github-stream]
    depends_on:
      kafka:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      DB_HOST:                 timescaledb
      DB_PORT:                 "5432"
      DB_NAME:                 github_events
      DB_USER:                 github
      DB_PASSWORD:             github_secret
    restart: unless-stopped

  # ── Grafana ─────────────────────────────────────────────────────
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    networks: [github-stream]
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      GF_SECURITY_ADMIN_USER:     admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_INSTALL_PLUGINS:         grafana-worldmap-panel,grafana-clock-panel
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /etc/grafana/provisioning/dashboards/github_events.json
    depends_on:
      timescaledb:
        condition: service_healthy
    restart: unless-stopped